## nginx access log parser
[[inputs.logparser]]
    ## log file to parse
    files = ["/var/log/nginx/access.log"]

    ## configure if file should read from the beginning
    from_beginning = false

    [inputs.logparser.grok]
        ## define grok pattern for log format
        patterns = ["%{COMBINED_LOG_FORMAT}"]

        ## name of outputted measurement -> may table name for influx/elasticsearch
        measurement = "amadeus_nginx_access"

## lumen log parser
[[inputs.logparser]]
    ## log file
    files = ["/var/log/app.log"]

    ## file should read from the beginning?
    from_beginning = false

    [inputs.logparser.grok]
        ## define pattern for log parsing
        patterns = ["%{APP_LOG}"]

        ## custom pattern defination for lumen log parsing
        custom_patterns = '''
            APP_LOG \[%{TIMESTAMP_ISO8601:timestamp}\] %{DATA:env}\.%{DATA:severity}: %{GREEDYDATA:message}
        '''

        ## name of measurement
        measurement = "amadeus_app_log"

## output parsed data to influxdb
[[outputs.influxdb]]
    ## configure influx
    urls = ["http://influxdb:8086"]
    ## database name
    database = "telegraf"

## output parsed data to kafka (producer)
#[[outputs.kafka]]
#    ## broker url(s)
#    brokers = ["kafka-broker:9092"]
#
#    ## topic for producer message
#    topic = "telegraf"
#
#    ## Telegraf tag for routing
#    routing_key = "access"
#
#    ## compression codec
#    compression_codec = 0
#
#    ## option uses to tell the broker how many replica acks it must see before responding
#    required_acks = -1
#
#    ## time to try to retry sending message
#    max_retry = 3
#
#    data_format = "influx"

## output parsed data to amqp
#[[outputs.amqp]]
#    ## url
#    url = "amqp://rabbit:5672/influxdb"
#
#    ## exchange
#    exchange = "telegraf"
#
#    ## Telegraf tag for routing
#    routing_tag = "access"
#
#    ## InfluxDb name
#    database = "telegraf"
#
#    data_format = "influx"
